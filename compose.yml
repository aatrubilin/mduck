services:
  ollama:
    image: ollama/ollama
    environment:
      OLLAMA_NUM_THREADS: 4
      OLLAMA_MAX_LOADED_MODELS: 1
      OLLAMA_KEEP_ALIVE: "-5m"
      OLLAMA_FLASH_ATTENTION: "false"
    volumes:
      - ./data/ollama:/root/.ollama
    networks:
      - mduck-net

  download-model:
    image: ollama/ollama
    volumes:
      - ./data/ollama:/root/.ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    env_file:
      - .env
    command: "pull ${OLLAMA__MODEL}"
    depends_on:
      - ollama
    networks:
      - mduck-net

  mduck:
    image: ghcr.io/aatrubilin/mduck:latest
    ports:
      - "8000:8000"
    env_file:
      - .env
    networks:
      - mduck-net
    depends_on:
      - download-model

networks:
  mduck-net:
