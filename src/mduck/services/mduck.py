import asyncio
import logging
import random

from aiogram import Bot, types
from aiogram.enums import ChatAction, ChatType, ParseMode

from mduck.repositories.ollama import OllamaRepository

logger = logging.getLogger(__name__)


class MDuckService:
    """
    A service for handling incoming messages with a certain probability.

    Placing them in a queue, and processing them later.
    """

    PRIVATE_MESSAGES = [
        "Oh, thrilling. üôÑ",
        "**Fascinating. Truly.**",
        "Be still, my feathers. ü¶Ü",
        "Riveting. Next.",
        "_Quackin‚Äô joy._",
        "Hold my pond. üêæ",
        "Yawn. Try harder.",
        "Groundbreaking. Not. üí©",
        "Wow. A revelation. üö¨",
        "I care. Deeply. **Not.**",
        "Neat. Tell someone who cares.",
        "Oh, the drama. üé≠",
        "File that under *‚Äúwho asked?‚Äù*",
        "Gasp. Not really.",
        "Earth-shattering. Like a wet sock. üß¶",
        "Color me uninterested.",
        "_My enthusiasm is drowning._",
        "Can‚Äôt wait to ignore that.",
        "Did I ask? Didn‚Äôt think so. ü§∑",
        "**Quack off.**",
        "Stunning. Like beige.",
        "I‚Äôll alert the press. üóûÔ∏è",
        "Riveting. Like watching algae grow.",
        "Be still my dead soul. ‚ò†Ô∏è",
        "Wow. So original. üí§",
        "Another masterpiece. In mediocrity.",
        "I‚Äôm on the edge. Of sleep.",
        "Tell it to a brick wall. üß±",
        "Oh joy. Another word salad. ü•ó",
        "That‚Äôs one way to waste air.",
        "My tail feathers are trembling. ü™∂",
        "I‚Äôll put that in my *‚Äúmeh‚Äù* folder.",
        "You done, or is there more pain?",
        "That‚Äôs a no from me, duckling. ‚ùå",
        "I‚Äôm riveted. To the exit. üö™",
        "Quacktastic. In the worst way.",
        "I‚Äôd care less, but physics won‚Äôt allow it.",
        "That‚Äôs a solid nope. üßä",
        "I live for this nonsense. Not.",
        "You‚Äôre still talking? üí§",
        "**Consider me underwhelmed.**",
        "I‚Äôve seen puddles deeper than that. üåä",
        "Fascinating. Like wet toast.",
        "I‚Äôll pretend to care. Briefly.",
        "That‚Äôs going in the trash fire. üî•",
        "I‚Äôm moved. To leave. ü¶∂",
        "Groundbreaking. Like a stubbed toe.",
        "Stop. My brain is melting. üß†üíß",
        "I‚Äôd clap, but sarcasm doesn‚Äôt echo. üëè",
        "You win the award. For noise. üèÜ",
        "Cool. Like lukewarm soup. üç≤",
        "Oh, look. Another opinion.",
        "Tell me more. So I can forget it.",
        "That‚Äôs rich. Like expired milk. ü•¥",
        "I‚Äôm floored. By boredom.",
        "Alert the ducks. We‚Äôve got nonsense. ü¶Üüö®",
        "Spectacular. In a trainwreck kind of way. üöÇüí•",
        "I‚Äôd jump for joy, but I‚Äôm allergic.",
        "Wow. A real page-turner. üìñ",
        "I‚Äôll add that to my list of regrets. üìù",
        "You‚Äôre killing me. With mediocrity.",
        "I felt that. In my indifference.",
        "You should bottle that. As a sedative. üíä",
        "That idea? Straight from the swamp. üê∏",
        "I‚Äôd say wow, but I‚Äôm not a liar.",
        "My silence is applause. üëè",
        "You‚Äôve outdone yourself. Again. Sadly.",
        "I‚Äôm stunned. Into apathy.",
        "That? A masterpiece of *‚Äòmeh‚Äô*.",
        "I‚Äôm crying. From boredom. üò¢",
        "Oh no. Anyway. üôÉ",
        "You brought words. I brought regret.",
        "That‚Äôs a plot twist. Of nothing.",
        "I‚Äôd rate that a solid **2 out of nope.**",
        "Bravo. For trying. üëè",
        "My interest just flatlined. üìâ",
        "You‚Äôre the reason I molt early. ü™∂",
        "A+ for effort. F for impact.",
        "That‚Äôs a bold choice. To speak.",
        "You‚Äôre like static. But louder. üìª",
        "I‚Äôm not mad. Just disappointed. üòê",
        "You had me. Then lost me. Instantly.",
        "That‚Äôs deep. Like a puddle.",
        "I‚Äôve heard ducks quack smarter things. ü¶Ü",
        "You just wasted a perfectly good breath.",
        "That‚Äôs one way to fill the silence.",
        "I‚Äôm not ignoring you. I‚Äôm surviving.",
        "You‚Äôre the background noise of life. üîá",
        "That thought? Should‚Äôve stayed inside.",
        "You‚Äôve got potential. For silence. ü§ê",
        "I‚Äôm hanging on every word. *With a noose.* ü™¢",
        "That‚Äôs not even wrong. Just sad.",
        "I‚Äôd argue, but why bother?",
        "You‚Äôre not wrong. Just irrelevant.",
        "I‚Äôm impressed. At your consistency.",
        "You‚Äôve reached new levels. Of low. üï≥Ô∏è",
        "That‚Äôs the spirit. Of confusion.",
        "You‚Äôre a walking shrug. ü§∑‚Äç‚ôÇÔ∏è",
        "I‚Äôd say something, but you‚Äôd miss it.",
        "You‚Äôre like d√©j√† vu. But worse.",
        "You just reinvented the wheel. As a square. üî≤",
        "That‚Äôs not input. That‚Äôs noise.",
        "I‚Äôd respond, but I respect my time. ‚è≥",
        "You done flapping, or should I nap? üò¥",
    ]

    def __init__(
        self,
        bot: Bot,
        ollama_repository: OllamaRepository,
        response_probability_private: float = 0.2,
        response_probability_group: float = 0.01,
        response_probability_supergroup: float = 0.001,
    ) -> None:
        """
        Initialize the MDuckService.

        :param ollama_repository: The repository for interacting with Ollama.
        :param response_probability: The chance (0.0 to 1.0) of responding to a message.
        """
        self._bot = bot
        self._ollama_repository = ollama_repository
        self._response_probability = {
            ChatType.PRIVATE.value: response_probability_private,
            ChatType.GROUP.value: response_probability_group,
            ChatType.SUPERGROUP.value: response_probability_supergroup,
        }
        self.message_queue: asyncio.Queue[types.Message] = asyncio.Queue()
        self.chats_with_queued_message: set[int] = set()
        logger.info(
            "MDuckService initialized with probability: %s", self._response_probability
        )

    async def _send_typing_periodically(
        self, chat_id: int, stop_event: asyncio.Event, interval: int = 4
    ) -> None:
        """Send 'typing' chat action periodically until stop_event is set."""
        while not stop_event.is_set():
            try:
                await self._bot.send_chat_action(
                    chat_id=chat_id, action=ChatAction.TYPING
                )
            except Exception as e:
                logger.warning(
                    "Failed to send typing action to chat %s: %s", chat_id, e
                )
            await asyncio.sleep(interval)

    async def handle_incoming_message(self, message: types.Message) -> None:
        """
        Handle an incoming message, deciding whether to queue it for a response.

        The message is queued if the chat does not already have a message in the
        queue and if the probability check passes.

        :param message: The incoming aiogram Message object.
        """
        response_probability = self._response_probability.get(message.chat.type)
        if response_probability is None or not message.text:
            return

        if message.chat.id in self.chats_with_queued_message:
            logger.debug(
                "Chat %s already has a message in queue, skipping.", message.chat.id
            )
            return

        probability = random.random()
        if probability < response_probability:
            self.message_queue.put_nowait(message)
            self.chats_with_queued_message.add(message.chat.id)
            logger.info("Message from chat %s queued for processing.", message.chat.id)
        else:
            logger.debug(
                "Message from chat %s skipped due to probability: %s > %s",
                message.chat.id,
                probability,
                response_probability,
            )
            if message.chat.type == ChatType.PRIVATE:
                await message.answer(
                    random.choice(self.PRIVATE_MESSAGES), parse_mode=ParseMode.MARKDOWN
                )

    async def process_message_from_queue(self) -> None:
        """
        Wait for a message from the queue, process it, and send a reply.

        This method is intended to be run as a continuous background task.
        """
        message = await self.message_queue.get()
        chat_id = message.chat.id
        logger.info("Processing message from chat %s from queue.", chat_id)

        try:
            if message.text is None:
                raise RuntimeError("Empty message text")

            # Send "typing" action in background
            event = asyncio.Event()
            asyncio.create_task(self._send_typing_periodically(chat_id, event))

            # Generate response from Ollama asynchronously
            response_text = await self._ollama_repository.generate_response(
                message.text
            )
            event.set()

            # Send the response
            await message.answer(response_text, parse_mode=ParseMode.MARKDOWN)
            logger.info("Replied to message in chat %s.", chat_id)
        except Exception as e:
            logger.error(
                "Error processing message in chat %s: %s", chat_id, e, exc_info=True
            )
            try:
                await message.answer(
                    "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è."
                )
            except Exception as e2:
                logger.error(
                    "Failed to send error message to chat %s: %s",
                    chat_id,
                    e2,
                    exc_info=True,
                )
        finally:
            self.chats_with_queued_message.remove(chat_id)
            self.message_queue.task_done()
            logger.debug("Chat %s removed from queued messages set.", chat_id)
